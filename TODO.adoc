:showtitle:
:icons: font

= TODO

Current status:

* implement disks
** done: create basic model types
** done: create API endpoints to create (sync?), get, list, delete (sync?)
** in progress: create API endpoints to attach, detach
*** working on disk_ensure() in ServerController
**** I'm not sure if it's even worth finishing what I've currently got or if I
     should just implement it all from scratch per note below about commonizing
     SimInstance and SimDisk.
**** we should give at least a passing thought to representing things internally
     _only_  with at-rest states and presenting not-at-rest states if there's a
     target next state that hasn't been applied.  i.e., get rid of Attaching and
     interpret that when we're in a detached state and going to Attached.
**** note: will want to commonize with SimInstance.  Both have constructor,
     transition(), transition_finish(), a notify function and a sim function on
     the ServerController.  This is going to be a bunch of work.
**** note: will also want to have disk contain AttachState (analogous to
     RuntimeState) that includes timestamp, generation number? server/instance
     uuid
**** Cases to handle include:
***** attach while creating
***** destroy while creating, attaching, detaching, or detached

API endpoints:

* `/disks` and related endpoints
* RFD 24: regions, AZs, etc
* (lots more)

Work queue (see also: existing GitHub issues):

* implement server controller as separate program (would be a better demo of
  what's really going on internally)
* do a demo????
* settle on an approach for modification of resources and implement it once
* document Dropshot
* write some design documents
* implement behavior of server restarting (e.g., server controller starting up)
** This probably isn't necessary for the big demo, but it would help validate
   some of the architectural choices.  Current thinking is that this will notify
   OXCP of the restart, and OXCP will find instances that are supposed to be on
   that server and run instance_ensure().  It will also want to do that for the
   disks associated with those instances.
* implement audit log
* implement alerts
* implement external user authentication
* implement external user authorization mechanism
* implement throttling and load shedding described in RFD 6
* implement hardening in RFD 10
* implement ETag / If-Match / If-None-Match
* implement limits for all types of resources
* polish pagination interface
** Decide if we want to use an opaque token or not.
** If we stick with NDJSON, use serde_json::StreamDeserializer.  Maybe we should
   just return a big object, though.
* integrate a real data storage backend
* implement scheme for API versioning
** how to identify the requested version -- header or URI?
** translators for older versions?
** integration of supported API versions into build artifact?
** Should all the uses of serde_json disallow unrecognized fields?  Should any?
* debugging/monitoring: Prometheus?
* debugging/monitoring: OpenTracing? OpenTelemetry?
* debugging/monitoring: Dynamic tracing?
* debugging/monitoring: Core files?
* Automated testing
** General API testing: there's a lot of boilerplate in hand-generated tests
   for each kind of resource.  Would it be reasonable / possible to have a sort
   of omnibus test that's given the OpenAPI spec (or something like it),
   creates a hierarchy with at least one of every possible resource, and does
   things like: For each possible resource
*** attempt to (create, get, put, delete) one with an invalid name
*** attempt to (GET, DELETE, PUT) one that does not exist
*** attempt to create one with invalid JSON
*** attempt to create one with a duplicate name of the one we know about
*** exercise list operation with marker and limit (may need to create many of them)
*** for each required input property:
**** attempt to create a resource without that property
*** for each input property: attempt to create a resource with invalid values
    for that property
*** list instances of that resource and expect to find the one we know about
*** GET the one instance we know about
*** DELETE the one instance we know about
*** GET the one instance we know about again and expect it to fail
*** list instances again and expect to find nothing

External dependencies / open questions:

* Should we consider switching to sync?
* Should we create a more first-class notion of objects in the API?
** This would be a good way to enforce built-in limits.
** This would be a good way to enforce uniformity of pagination.
** If each resource provides a way to construct ETags, we could provide
   automatic implementation of If-Match, etc.
** With the right interface, we could provide automatic implementations of PUT
   or PATCH with JSON Merge Patch and JSON Patch given any one of these.
* would like to require that servers have unique, immutable uuids
* TLS:
** How will we do TLS termination?
** How will we manage server certificates?
** How will we manage client certificates?
* what data storage backend will we use?
* what does bootstrapping / key management look like?
* what does internal authorization look like?

Other activities:

* Performance testing
* Stress testing
* Fault testing / under load
* Fuzz testing
* Security review

Nice-to-haves:

* API consistency checks: e.g., camel case every where
